# Website Crawler

This project is a simple website crawler that extracts all the links from a given website. It fetches the content of the website, parses it to find all the links, and saves them to a file.

## Files

- `main.py`: The main script that performs the crawling.
- `requirements.txt`: The list of dependencies required for the project.

## Installation

1. Clone the repository:

   ```sh
   git clone https://github.com/username/repository.git
   cd repository
